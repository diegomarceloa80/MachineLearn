# Midterm Project
## Author: Diego Altamirano P.
## Date: 2025-10-04

### Registro de las Estaciones Metereológicas Instituto de Investigación Geológico y Energético IIGE
El data set contiene datos de las estaciones meteorológicas del Instituto de Investigación Geológico y Energético (IIGE) de Ecuador. El conjunto de datos incluye diversas variables climáticas y meteorológicas registradas en diferentes estaciones a lo largo del tiempo. Estas variables pueden incluir temperatura, humedad, precipitación, velocidad del viento, entre otras.

# 1 Modelo de Regresión lineal  con Scikit-Learn
# importar librerías
```{python}
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import pandas as pd
```
# 2. cargar dataset csv
```{python}
data = pd.read_csv("iige005_san-gabriel.csv", encoding="latin1")
data.head()
```
### obtener información general del DataFrame
```{python}
print(data.info()) 
```
### Describir el dataset
```{python}
print(data.describe())
```
### Para el estudio requerimos que las características sean numéricas realizamos una transformación.
```{python}
cols_to_numeric = data.columns[3:]
data[cols_to_numeric] = data[cols_to_numeric].apply(pd.to_numeric, errors='coerce')
```
### Comprabos la transformación 
```{python}
print(data.info())
```
### descartamos las columnas que no aportan en el análisis 
```{python}
data = data.iloc[:, 3:] #    
```

```{python}
data = data.drop(columns=["WD(most)", "Max_time"], errors="ignore")
```
# eliminar filas con valores nulos
```{python}
data = data.dropna()
```
# 3. Split dataset
```{python}
X = data.drop(columns=["Rainfall"])  # Variables predictoras
y = data["Rainfall"]  # Variable objetivo  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train.shape, X_test.shape, y_train.shape, y_test.shape
```

# pipeline regression lineal
```{python}

pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("lin_reg", LinearRegression())
])

```
# 4. Train model
```{python}
pipeline.fit(X_train, y_train)  
```
# 5. Make predictions
```{python}
y_pred_regresion = pipeline.predict(X_test)   
```

# 6. Evaluate model
```{python}
mse = mean_squared_error(y_test, y_pred_regresion)
r2 = r2_score(y_test, y_pred_regresion)
mse, r2
print(f"MSE: {mse}")
print(f"R²: {r2}")
```
# 7. Visualize results
```{python}
import matplotlib.pyplot as plt

plt.scatter(y_test, y_pred_regresion)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted")
plt.show()
``` 

# grafica de histogramas
```{python}
plt.hist(y_test - y_pred_regresion, bins=30)
plt.xlabel("Error")
plt.ylabel("Frecuencia")
plt.title("Histograma de Errores")
plt.show()  
```
# grafico de headmap
```{python}
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.heatmap(data.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Mapa de Calor de Correlaciones")
plt.show()  
```

# Parte 2 Clasificación Logística

## Líneas activas por tecnología
Agencia de Regulación y Control de las Telecomunicaciones ARCOTEL

Contiene los datos de lineas activas de tecnología del Servicio Móvil Avanzado.

### El siguiente dataset Líneas Activas por Tecnología de ARCOTEL (arcotel.csv) para realizar este ejercicio de clasificación binaria. Este dataset contiene 258 registros (un registro por operador y por mes entre 2009 y 2021)

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
```

```{python}
# Cargar el dataset
data_clasi = pd.read_csv("arcotel.csv")
```

```{python}
# explacion data info
print(data_clasi.info())
```

```{python}
print(data_clasi.describe())
```
### Definición del Problema de Clasificación Binaria
El objetivo es predecir si un mes dado (registrado por un operador) está dominado por la tecnología de Cuarta Generación (4G).

Variable Objetivo (Y): Dominio 4G (Binaria).

Clase 1 (Positivo): LTE (líneas 4G) supera la suma de líneas 3G (UMTS+HSPA+).

Clase 0 (Negativo): LTE es igual o menor a la suma de líneas 3G o si el dominio es de tecnologías más antiguas (GSMA).

Variables Predictoras (X): Las líneas activas en tecnologías más antiguas y el operador.

cdma (Legado), gsma (2G), umts (3G), hspa+ (3G/3.5G), y nombre (Operador).
```{python}
# 1. Creación de la Variable Objetivo Binaria (Y)
# Clase 1 si LTE > (UMTS + HSPA+), Clase 0 en caso contrario
data_clasi['Total_3G'] = data_clasi['umts'] + data_clasi['hspa+']
data_clasi['Dominio_4G'] = (data_clasi['lte'] > data_clasi['Total_3G']).astype(int)

# 2. Definición de Variables (X y Y)
features = ['cdma', 'gsma', 'umts', 'hspa+', 'nombre']
target = 'Dominio_4G'

X = data_clasi[features]
y = data_clasi[target]

# 3. Separación de conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# 4. Definición de preprocesamiento para variables numéricas y categóricas
numerical_features = ['cdma', 'gsma', 'umts', 'hspa+']
categorical_features = ['nombre']

# Pipeline de preprocesamiento: Escalado (StandardScaler) para numéricas y One-Hot Encoding para categóricas
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough'
)

# 5. Creación y entrenamiento del Pipeline (Preprocesamiento + Modelo)
model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')) # Usamos class_weight='balanced' para mitigar el desbalance entre 3G y 4G.
])

model_pipeline.fit(X_train, y_train)

# Predicciones
y_pred = model_pipeline.predict(X_test)
y_proba = model_pipeline.predict_proba(X_test)[:, 1]
```

```{python}
# Cálculo de Métricas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

```

#### Métricas de Evaluación del Modelo
Métrica	Valor	Interpretación
Accuracy (Exactitud)	0.8205	El 82.05% de las predicciones fueron correctas (Dominio 4G vs. 3G/menos).
Precision (Precisión)	0.7727	Cuando el modelo predijo "Dominio 4G", acertó el 77.27% de las veces.
Recall (Sensibilidad)	0.8500	El modelo identificó correctamente el 85.00% de todos los meses donde realmente hubo Dominio 4G.
F1 Score	0.8095	Media armónica entre Precisión y Recall (buen equilibrio de la clasificación).
Área bajo la Curva ROC (AUC)	0.8653	El modelo tiene una buena capacidad para distinguir entre las dos clases.

```{python}
# Visualización de la Matriz de Confusión
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Dominio 4G (0)', 'Dominio 4G (1)'],
            yticklabels=['No Dominio 4G (0)', 'Dominio 4G (1)'])
plt.xlabel('Predicción')
plt.ylabel('Valor Real')
plt.title('Matriz de Confusión (Regresión Logística)')
plt.show()
```
#### Matriz de Confusión
Verdaderos Positivos (TP): 17 (Meses donde se predijo Dominio 4G y fue correcto).

Verdaderos Negativos (TN): 47 (Meses donde se predijo No Dominio 4G y fue correcto).

Falsos Positivos (FP): 5 (El modelo predijo Dominio 4G cuando en realidad fue 3G/menos).

Falsos Negativos (FN): 3 (El modelo predijo 3G/menos cuando en realidad fue Dominio 4G).

```{python}
# Visualización de la Curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (área = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Tasa de Falsos Positivos (FPR)')
plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
plt.title('Curva Característica Operativa del Receptor (ROC)')
plt.legend(loc="lower right")
plt.show()
```
#### Curva ROC
El valor de AUC=0.8653 (área bajo la curva) es cercano a 1.0, lo que indica que el modelo es significativamente mejor que una suposición aleatoria (donde AUC=0.5). La curva se eleva rápidamente hacia la esquina superior izquierda, confirmando un buen rendimiento del clasificador.